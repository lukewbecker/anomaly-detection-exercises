{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credentials loaded successfully\n",
      "End of file.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# splitting data:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# web-based requests\n",
    "import requests\n",
    "\n",
    "# Importing the os library specifically for reading the csv once I've created the file in my working directory.\n",
    "import os\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquire data:\n",
    "\n",
    "url = 'https://gist.githubusercontent.com/ryanorsinger/19bc7eccd6279661bd13307026628ace/raw/e4b5d6787015a4782f96cad6d1d62a8bdbac54c7/lemonade.csv'\n",
    "    \n",
    "df = pd.read_csv(url)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Flyers</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/17</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/17</td>\n",
       "      <td>Monday</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1.33</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/17</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>34.5</td>\n",
       "      <td>1.33</td>\n",
       "      <td>27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/4/17</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>44.1</td>\n",
       "      <td>1.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/5/17</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>42.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date        Day  Temperature  Rainfall  Flyers  Price  Sales\n",
       "0  1/1/17     Sunday         27.0      2.00      15    0.5     10\n",
       "1  1/2/17     Monday         28.9      1.33      15    0.5     13\n",
       "2  1/3/17    Tuesday         34.5      1.33      27    0.5     15\n",
       "3  1/4/17  Wednesday         44.1      1.05      28    0.5     17\n",
       "4  1/5/17   Thursday         42.4      1.00      33    0.5     18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all column headers in lowercase:\n",
    "\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 365 entries, 0 to 364\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   date         365 non-null    object \n",
      " 1   day          365 non-null    object \n",
      " 2   temperature  365 non-null    float64\n",
      " 3   rainfall     365 non-null    float64\n",
      " 4   flyers       365 non-null    int64  \n",
      " 5   price        365 non-null    float64\n",
      " 6   sales        365 non-null    int64  \n",
      "dtypes: float64(3), int64(2), object(2)\n",
      "memory usage: 20.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((204, 7), (88, 7), (73, 7))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = split_data(df)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='temperature', y='sales', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('day').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    plt.figure(figsize = (4, 2))\n",
    "    plt.hist(df[col])\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == 'float64':\n",
    "        plt.figure(figsize = (4, 2))\n",
    "        plt.hist(df[col])\n",
    "        plt.title(col)\n",
    "        plt.show()\n",
    "    elif df[col].dtype == 'int64':\n",
    "        plt.figure(figsize = (4, 2))\n",
    "        plt.hist(df[col])\n",
    "        plt.title(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use John's way of getting a list of columns that are the \"correct\" dtype:\n",
    "\n",
    "lst = [column for column in df.columns if df[f'{column}'].dtype in ('int64','float64')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype in ('int64','float64'):\n",
    "        plt.figure(figsize = (4, 2))\n",
    "        plt.hist(df[col])\n",
    "        plt.title(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaway:\n",
    "\n",
    "- Looks like temp and rainfall are somewhat normally distributed, but with a skew (due to outliers).\n",
    "- I should be good using the outlier detection on those columns since they do have a normal(ish) distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using lemonade.csv dataset and focusing on continuous variables:\n",
    "\n",
    "- Use the IQR Range Rule and the upper and lower bounds to identify the lower outliers of each column of lemonade.csv, using the multiplier of 1.5. Do these lower outliers make sense? Which outliers should be kept?\n",
    "- Use the IQR Range Rule and the upper and lower bounds to identify the upper outliers of each column of lemonade.csv, using the multiplier of 1.5. Do these lower outliers make sense? Which outliers should be kept?\n",
    "- Using the multiplier of 3, IQR Range Rule, and the lower and upper bounds, identify the outliers below the lower bound in each colum of lemonade.csv. Do these lower outliers make sense? Which outliers should be kept?\n",
    "- Using the multiplier of 3, IQR Range Rule, and the lower and upper bounds, identify the outliers above the upper_bound in each colum of lemonade.csv. Do these upper outliers make sense? Which outliers should be kept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data:\n",
    "\n",
    "def split_data(df):\n",
    "    '''\n",
    "    This function will split a dataframe into 3 dataframes: train, validate and test.\n",
    "    The random state is set to 123 by default, the validate test_size argument is set to .2, and the test test_size is set to .3.\n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size = .2, random_state = 123)\n",
    "    train, validate = train_test_split(train_validate, test_size = .3, random_state = 123)\n",
    "    return train, validate, test\n",
    "    print(train.shape, validate.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split_data(df)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example purposes, calculating temp manually just eyeballing the above table:\n",
    "\n",
    "q1, q3 = df1.temperature.quantile([.25, .75])\n",
    "iqr = q3 - q1\n",
    "iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_fence = q1 - multiplier * iqr\n",
    "lower_fence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_fence = q3 + multiplier * iqr\n",
    "upper_fence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Temperature step by step\n",
    "- So I know what I'm doing for when I build my function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.temperature[df1.temperature >= upper_fence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.temperature[df1.temperature <= lower_fence].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.temperature >= upper_fence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.temperature[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(10-9, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(10-11, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upper_outliers(s, k):\n",
    "    '''\n",
    "    Given a series and a cutoff value, k, returns the upper outliers for the\n",
    "    series.\n",
    "\n",
    "    The values returned will be either 0 (if the point is not an outlier), or a\n",
    "    number that indicates how far away from the upper bound the observation is.\n",
    "    '''\n",
    "    \n",
    "    q1, q3 = s.quantile([.25, .75])\n",
    "    iqr = q3 - q1\n",
    "    upper_fence = q3 + k * iqr\n",
    "    return s.apply(lambda x: max([x - upper_fence, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lower_outliers(s, k):\n",
    "    '''\n",
    "    Given a series and a cutoff value, k, returns the lower outliers for the\n",
    "    series.\n",
    "\n",
    "    The values returned will be either 0 (if the point is not an outlier), or a\n",
    "    number that indicates how far away from the lower bound the observation is.\n",
    "    '''\n",
    "    \n",
    "    q1, q3 = s.quantile([.25, .75])\n",
    "    iqr = q3 - q1\n",
    "    lower_fence = q1 - k * iqr\n",
    "    return s.apply(lambda x: max([lower_fence - x, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding columns for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_upper_outlier_columns(df, k):\n",
    "    '''\n",
    "    Add a column with the suffix _outliers for all the numeric columns\n",
    "    in the given dataframe.\n",
    "    '''\n",
    "    # outlier_cols = {col + '_outliers': get_upper_outliers(df[col], k)\n",
    "    #                 for col in df.select_dtypes('number')}\n",
    "    # return df.assign(**outlier_cols)\n",
    "\n",
    "    for col in df.select_dtypes('number'):\n",
    "        if not col.endswith('_outliers', -9):\n",
    "            df[col + '_up_outliers'] = get_upper_outliers(df[col], k)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lower_outlier_columns(df, k):\n",
    "    '''\n",
    "    Add a column with the suffix _outliers for all the numeric columns\n",
    "    in the given dataframe.\n",
    "    '''\n",
    "    # outlier_cols = {col + '_outliers': get_upper_outliers(df[col], k)\n",
    "    #                 for col in df.select_dtypes('number')}\n",
    "    # return df.assign(**outlier_cols)\n",
    "\n",
    "    for col in df.select_dtypes('number'):\n",
    "        if not col.endswith('_outliers', (len('_outliers') * -1)):\n",
    "            df[col + '_low_outliers'] = get_upper_outliers(df[col], k)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_upper_outlier_columns(df1, 1.5)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_lower_outlier_columns(df1, 1.5)\n",
    "df1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outlier_cols = [col for col in df1 if col.endswith('_outliers')]\n",
    "for col in outlier_cols:\n",
    "    print('~~~\\n' + col)\n",
    "    data = df1[col][df1[col] > 0]\n",
    "    print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaways:\n",
    "\n",
    "- The sales, flyers, and rainfall outliers are all most likely due to those columns have a fairly significant skew in their distributions. Looking above at the charts, it is apparent that there is a skew, thus using the IQR Range rule to isoluate outliers will produce a larger number of outliers, compared to a truly normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolating the outliers\n",
    "\n",
    "- Do these outliers make sense to get rid of or keep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.temperature_up_outliers != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.rainfall_up_outliers != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.flyers_up_outliers != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.price_up_outliers != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.sales_up_outliers != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.temperature_low_outliers != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.rainfall_low_outliers != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.flyers_low_outliers != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.price_low_outliers != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.sales_low_outliers != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaways:\n",
    "\n",
    "- Rainfall has a lot of outliers, but that is most likely because rainfall is not normally distributed or has a skew in it's distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to print the outlier rows\n",
    "\n",
    "for col in up_outlier:\n",
    "    print('~~~\\n' + col)\n",
    "    data = df1[col][df1[col] > 0]\n",
    "    print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_outlier = [col for col in df1.columns if col.endswith('_up_outliers', -12)]\n",
    "up_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 3 as the multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_upper_outlier_columns(df2, 3)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_lower_outlier_columns(df2, 3)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outlier_cols = [col for col in df2 if col.endswith('_outliers')]\n",
    "for col in outlier_cols:\n",
    "    print('~~~\\n' + col)\n",
    "    data = df2[col][df2[col] > 0]\n",
    "    print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaways:\n",
    "\n",
    "- Same results as above; but the distance of the outliers is slightly lower as one would expect with a larger multiplier for the standard deviation calculation.\n",
    "\n",
    "- The `rainfall` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = [col for col in df2.columns if col.endswith('_outliers', -9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_cols[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given some data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "x = np.random.normal(50, 40, size=1000)\n",
    "\n",
    "# Calculate the z-score \n",
    "zscores = pd.Series((x - x.mean()) / x.std())\n",
    "\n",
    "# Finds all of the observations two standard deviations or more.\n",
    "x[zscores.abs() >= 2]\n",
    "\n",
    "# Finds all of the observations three standard deviations or more\n",
    "x[zscores.abs() >= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identify if any columns in lemonade.csv are normally distributed. For normally distributed columns:\n",
    "\n",
    "- Use a 2 sigma decision rule to isolate the outliers.\n",
    "- Do these make sense?\n",
    "- Should certain outliers be kept or removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing charts again to isolate which distributions are normal:\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in ('int64','float64'):\n",
    "        plt.figure(figsize = (4, 2))\n",
    "        plt.hist(df[col])\n",
    "        plt.title(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result: `temperature`, `rainfall`, and `flyers` are fairly normally distributed (with a skew)\n",
    "\n",
    "- z-score relies on the distributions being normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dist = ['temperature', 'rainfall', 'flyers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.temperature\n",
    "zscores = (x - x.mean()) / x.std()\n",
    "\n",
    "zdf = pd.DataFrame()\n",
    "zdf[\"x\"] = x\n",
    "zdf[\"zscore\"] = abs(zscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking first at all values that are 1.5 std. dev from the mean:\n",
    "zdf[zscores >= 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now looking first at all values that are 2 and 3 std. dev from the mean:\n",
    "zdf[zscores >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf[zscores >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
